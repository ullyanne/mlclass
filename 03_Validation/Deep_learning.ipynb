{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D1r5e88LY8-2"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from pycaret.datasets import get_data\n",
        "from pycaret.classification import *\n",
        "# from pycaret.regression import load_model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-r3cBYL8Y8-4"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('abalone_dataset.csv')\n",
        "\n",
        "dummies = pd.get_dummies(data['sex'])\n",
        "\n",
        "dummies.columns = ['male', 'female', 'other']\n",
        "\n",
        "data = pd.concat([data, dummies], axis=1)\n",
        "\n",
        "data = data.drop('sex', axis=1)\n",
        "data = data.drop('male', axis=1)\n",
        "data = data.drop('female', axis=1)\n",
        "\n",
        "y = data.type\n",
        "X = data.drop(['type'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DuIVnXIzY8-6"
      },
      "outputs": [],
      "source": [
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_dim=8, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(1024, input_dim=8, activation='relu'))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dense(256, activation='relu'))\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(32, activation='relu'))\n",
        "model2.add(Dense(16, activation='relu'))\n",
        "model2.add(Dense(8, activation='relu'))\n",
        "model2.add(Dense(4, activation='relu'))\n",
        "model2.add(Dense(2, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "105/105 [==============================] - 5s 10ms/step - loss: 0.4958 - accuracy: 0.7720\n",
            "Epoch 2/30\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.4515 - accuracy: 0.8228\n",
            "Epoch 3/30\n",
            "105/105 [==============================] - 1s 12ms/step - loss: 0.4195 - accuracy: 0.8247\n",
            "Epoch 4/30\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3819 - accuracy: 0.8314\n",
            "Epoch 5/30\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3781 - accuracy: 0.8301\n",
            "Epoch 6/30\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3664 - accuracy: 0.8416\n",
            "Epoch 7/30\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3746 - accuracy: 0.8378\n",
            "Epoch 8/30\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3672 - accuracy: 0.8378\n",
            "Epoch 9/30\n",
            "105/105 [==============================] - 1s 13ms/step - loss: 0.3683 - accuracy: 0.8394\n",
            "Epoch 10/30\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.3689 - accuracy: 0.8423\n",
            "Epoch 11/30\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3641 - accuracy: 0.8410\n",
            "Epoch 12/30\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3732 - accuracy: 0.8327\n",
            "Epoch 13/30\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3612 - accuracy: 0.8458\n",
            "Epoch 14/30\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3613 - accuracy: 0.8400\n",
            "Epoch 15/30\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.3565 - accuracy: 0.8458\n",
            "Epoch 16/30\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3584 - accuracy: 0.8429\n",
            "Epoch 17/30\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3575 - accuracy: 0.8384\n",
            "Epoch 18/30\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3534 - accuracy: 0.8477\n",
            "Epoch 19/30\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3544 - accuracy: 0.8448\n",
            "Epoch 20/30\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3572 - accuracy: 0.8461\n",
            "Epoch 21/30\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3550 - accuracy: 0.8410\n",
            "Epoch 22/30\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3551 - accuracy: 0.8467\n",
            "Epoch 23/30\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3475 - accuracy: 0.8442\n",
            "Epoch 24/30\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3593 - accuracy: 0.8442\n",
            "Epoch 25/30\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3497 - accuracy: 0.8448\n",
            "Epoch 26/30\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3515 - accuracy: 0.8455\n",
            "Epoch 27/30\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.3533 - accuracy: 0.8461\n",
            "Epoch 28/30\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3619 - accuracy: 0.8439\n",
            "Epoch 29/30\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3503 - accuracy: 0.8471\n",
            "Epoch 30/30\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3474 - accuracy: 0.8426\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x23d49839d90>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "y_train = y.replace(3, 2)-1\n",
        "model.fit(X, y_train, epochs=30, batch_size=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T8m1NnATY8-8"
      },
      "outputs": [],
      "source": [
        "aux = pd.concat([X, y], axis=1)\n",
        "mask = aux['type'] != 1\n",
        "data_23 = aux[mask]\n",
        "\n",
        "y_train_23 = data_23.type-2\n",
        "X_train_23 = data_23.drop(['type'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformation Pipeline and Model Successfully Loaded\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=FastMemory(location=C:\\Users\\Rafae\\AppData\\Local\\Temp\\joblib),\n",
              "         steps=[(&#x27;label_encoding&#x27;,\n",
              "                 TransformerWrapperWithInverse(transformer=LabelEncoder())),\n",
              "                (&#x27;numerical_imputer&#x27;,\n",
              "                 TransformerWrapper(include=[&#x27;length&#x27;, &#x27;diameter&#x27;, &#x27;height&#x27;,\n",
              "                                             &#x27;whole_weight&#x27;, &#x27;shucked_weight&#x27;,\n",
              "                                             &#x27;viscera_weight&#x27;, &#x27;shell_weight&#x27;,\n",
              "                                             &#x27;other&#x27;],\n",
              "                                    transformer=SimpleImputer())),\n",
              "                (&#x27;categorical_imputer&#x27;,\n",
              "                 TransformerWrapper(include=[],\n",
              "                                    transformer=SimpleImputer(strategy=&#x27;most_frequent&#x27;))),\n",
              "                (&#x27;trained_model&#x27;, LinearDiscriminantAnalysis())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=FastMemory(location=C:\\Users\\Rafae\\AppData\\Local\\Temp\\joblib),\n",
              "         steps=[(&#x27;label_encoding&#x27;,\n",
              "                 TransformerWrapperWithInverse(transformer=LabelEncoder())),\n",
              "                (&#x27;numerical_imputer&#x27;,\n",
              "                 TransformerWrapper(include=[&#x27;length&#x27;, &#x27;diameter&#x27;, &#x27;height&#x27;,\n",
              "                                             &#x27;whole_weight&#x27;, &#x27;shucked_weight&#x27;,\n",
              "                                             &#x27;viscera_weight&#x27;, &#x27;shell_weight&#x27;,\n",
              "                                             &#x27;other&#x27;],\n",
              "                                    transformer=SimpleImputer())),\n",
              "                (&#x27;categorical_imputer&#x27;,\n",
              "                 TransformerWrapper(include=[],\n",
              "                                    transformer=SimpleImputer(strategy=&#x27;most_frequent&#x27;))),\n",
              "                (&#x27;trained_model&#x27;, LinearDiscriminantAnalysis())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">label_encoding: TransformerWrapperWithInverse</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapperWithInverse(transformer=LabelEncoder())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(include=[&#x27;length&#x27;, &#x27;diameter&#x27;, &#x27;height&#x27;, &#x27;whole_weight&#x27;,\n",
              "                            &#x27;shucked_weight&#x27;, &#x27;viscera_weight&#x27;, &#x27;shell_weight&#x27;,\n",
              "                            &#x27;other&#x27;],\n",
              "                   transformer=SimpleImputer())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(include=[],\n",
              "                   transformer=SimpleImputer(strategy=&#x27;most_frequent&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(memory=FastMemory(location=C:\\Users\\Rafae\\AppData\\Local\\Temp\\joblib),\n",
              "         steps=[('label_encoding',\n",
              "                 TransformerWrapperWithInverse(transformer=LabelEncoder())),\n",
              "                ('numerical_imputer',\n",
              "                 TransformerWrapper(include=['length', 'diameter', 'height',\n",
              "                                             'whole_weight', 'shucked_weight',\n",
              "                                             'viscera_weight', 'shell_weight',\n",
              "                                             'other'],\n",
              "                                    transformer=SimpleImputer())),\n",
              "                ('categorical_imputer',\n",
              "                 TransformerWrapper(include=[],\n",
              "                                    transformer=SimpleImputer(strategy='most_frequent'))),\n",
              "                ('trained_model', LinearDiscriminantAnalysis())])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Linear_Discriminant_Analysis = load_model('Linear_Discriminant_Analysis')\n",
        "#Linear Discriminant Analysis\n",
        "Linear_Discriminant_Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>diameter</th>\n",
              "      <th>height</th>\n",
              "      <th>whole_weight</th>\n",
              "      <th>shucked_weight</th>\n",
              "      <th>viscera_weight</th>\n",
              "      <th>shell_weight</th>\n",
              "      <th>other</th>\n",
              "      <th>type</th>\n",
              "      <th>prediction_label</th>\n",
              "      <th>prediction_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.535</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.1530</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.550</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.170</td>\n",
              "      <td>0.8100</td>\n",
              "      <td>0.3170</td>\n",
              "      <td>0.1570</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.700</td>\n",
              "      <td>0.575</td>\n",
              "      <td>0.205</td>\n",
              "      <td>1.7730</td>\n",
              "      <td>0.6050</td>\n",
              "      <td>0.4470</td>\n",
              "      <td>0.538</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.400</td>\n",
              "      <td>0.305</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.2970</td>\n",
              "      <td>0.1080</td>\n",
              "      <td>0.0705</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.7142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.620</td>\n",
              "      <td>0.480</td>\n",
              "      <td>0.165</td>\n",
              "      <td>1.0125</td>\n",
              "      <td>0.5325</td>\n",
              "      <td>0.4365</td>\n",
              "      <td>0.324</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.8386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3126</th>\n",
              "      <td>0.620</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.180</td>\n",
              "      <td>1.2330</td>\n",
              "      <td>0.5920</td>\n",
              "      <td>0.2740</td>\n",
              "      <td>0.322</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3127</th>\n",
              "      <td>0.545</td>\n",
              "      <td>0.405</td>\n",
              "      <td>0.175</td>\n",
              "      <td>0.9800</td>\n",
              "      <td>0.2585</td>\n",
              "      <td>0.2070</td>\n",
              "      <td>0.380</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3128</th>\n",
              "      <td>0.655</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.185</td>\n",
              "      <td>1.2590</td>\n",
              "      <td>0.4870</td>\n",
              "      <td>0.2215</td>\n",
              "      <td>0.445</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.8012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3130</th>\n",
              "      <td>0.520</td>\n",
              "      <td>0.410</td>\n",
              "      <td>0.155</td>\n",
              "      <td>0.7270</td>\n",
              "      <td>0.2910</td>\n",
              "      <td>0.1835</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3131</th>\n",
              "      <td>0.640</td>\n",
              "      <td>0.480</td>\n",
              "      <td>0.195</td>\n",
              "      <td>1.1435</td>\n",
              "      <td>0.4915</td>\n",
              "      <td>0.2345</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2054 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
              "0      0.535     0.420   0.150        0.6995          0.2575          0.1530   \n",
              "3      0.550     0.450   0.170        0.8100          0.3170          0.1570   \n",
              "5      0.700     0.575   0.205        1.7730          0.6050          0.4470   \n",
              "6      0.400     0.305   0.085        0.2970          0.1080          0.0705   \n",
              "7      0.620     0.480   0.165        1.0125          0.5325          0.4365   \n",
              "...      ...       ...     ...           ...             ...             ...   \n",
              "3126   0.620     0.510   0.180        1.2330          0.5920          0.2740   \n",
              "3127   0.545     0.405   0.175        0.9800          0.2585          0.2070   \n",
              "3128   0.655     0.525   0.185        1.2590          0.4870          0.2215   \n",
              "3130   0.520     0.410   0.155        0.7270          0.2910          0.1835   \n",
              "3131   0.640     0.480   0.195        1.1435          0.4915          0.2345   \n",
              "\n",
              "      shell_weight  other  type  prediction_label  prediction_score  \n",
              "0            0.240      0     1                 3            0.5476  \n",
              "3            0.220      0     1                 3            0.5862  \n",
              "5            0.538      0     1                 3            0.9623  \n",
              "6            0.100      0     0                 2            0.7142  \n",
              "7            0.324      0     0                 2            0.8386  \n",
              "...            ...    ...   ...               ...               ...  \n",
              "3126         0.322      0     0                 2            0.5694  \n",
              "3127         0.380      0     1                 3            0.9174  \n",
              "3128         0.445      0     1                 3            0.8012  \n",
              "3130         0.235      0     1                 3            0.5047  \n",
              "3131         0.353      0     0                 3            0.5928  \n",
              "\n",
              "[2054 rows x 11 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_model(Linear_Discriminant_Analysis, data=data_23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformation Pipeline and Model Successfully Loaded\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=FastMemory(location=C:\\Users\\Rafae\\AppData\\Local\\Temp\\joblib),\n",
              "         steps=[(&#x27;label_encoding&#x27;,\n",
              "                 TransformerWrapperWithInverse(transformer=LabelEncoder())),\n",
              "                (&#x27;numerical_imputer&#x27;,\n",
              "                 TransformerWrapper(include=[&#x27;length&#x27;, &#x27;diameter&#x27;, &#x27;height&#x27;,\n",
              "                                             &#x27;whole_weight&#x27;, &#x27;shucked_weight&#x27;,\n",
              "                                             &#x27;viscera_weight&#x27;, &#x27;shell_weight&#x27;,\n",
              "                                             &#x27;other&#x27;],\n",
              "                                    transformer=SimpleImputer())),\n",
              "                (&#x27;categorical_imputer&#x27;,\n",
              "                 TransformerWrapper(include=[],\n",
              "                                    transformer=SimpleImputer(strategy=&#x27;most_frequent&#x27;))),\n",
              "                (&#x27;trained_model&#x27;,\n",
              "                 ExtraTreesClassifier(n_jobs=-1, random_state=123))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=FastMemory(location=C:\\Users\\Rafae\\AppData\\Local\\Temp\\joblib),\n",
              "         steps=[(&#x27;label_encoding&#x27;,\n",
              "                 TransformerWrapperWithInverse(transformer=LabelEncoder())),\n",
              "                (&#x27;numerical_imputer&#x27;,\n",
              "                 TransformerWrapper(include=[&#x27;length&#x27;, &#x27;diameter&#x27;, &#x27;height&#x27;,\n",
              "                                             &#x27;whole_weight&#x27;, &#x27;shucked_weight&#x27;,\n",
              "                                             &#x27;viscera_weight&#x27;, &#x27;shell_weight&#x27;,\n",
              "                                             &#x27;other&#x27;],\n",
              "                                    transformer=SimpleImputer())),\n",
              "                (&#x27;categorical_imputer&#x27;,\n",
              "                 TransformerWrapper(include=[],\n",
              "                                    transformer=SimpleImputer(strategy=&#x27;most_frequent&#x27;))),\n",
              "                (&#x27;trained_model&#x27;,\n",
              "                 ExtraTreesClassifier(n_jobs=-1, random_state=123))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">label_encoding: TransformerWrapperWithInverse</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapperWithInverse(transformer=LabelEncoder())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(include=[&#x27;length&#x27;, &#x27;diameter&#x27;, &#x27;height&#x27;, &#x27;whole_weight&#x27;,\n",
              "                            &#x27;shucked_weight&#x27;, &#x27;viscera_weight&#x27;, &#x27;shell_weight&#x27;,\n",
              "                            &#x27;other&#x27;],\n",
              "                   transformer=SimpleImputer())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_imputer: TransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>TransformerWrapper(include=[],\n",
              "                   transformer=SimpleImputer(strategy=&#x27;most_frequent&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_jobs=-1, random_state=123)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(memory=FastMemory(location=C:\\Users\\Rafae\\AppData\\Local\\Temp\\joblib),\n",
              "         steps=[('label_encoding',\n",
              "                 TransformerWrapperWithInverse(transformer=LabelEncoder())),\n",
              "                ('numerical_imputer',\n",
              "                 TransformerWrapper(include=['length', 'diameter', 'height',\n",
              "                                             'whole_weight', 'shucked_weight',\n",
              "                                             'viscera_weight', 'shell_weight',\n",
              "                                             'other'],\n",
              "                                    transformer=SimpleImputer())),\n",
              "                ('categorical_imputer',\n",
              "                 TransformerWrapper(include=[],\n",
              "                                    transformer=SimpleImputer(strategy='most_frequent'))),\n",
              "                ('trained_model',\n",
              "                 ExtraTreesClassifier(n_jobs=-1, random_state=123))])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Extra_Trees_Classifier = load_model('Extra_Trees_Classifier')\n",
        "#Extra_Trees_Classifier\n",
        "Extra_Trees_Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# predict_model(Extra_Trees_Classifier, data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "69/69 [==============================] - 3s 9ms/step - loss: 0.6898 - accuracy: 0.5448\n",
            "Epoch 2/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6809 - accuracy: 0.5798\n",
            "Epoch 3/30\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.6820 - accuracy: 0.5808\n",
            "Epoch 4/30\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.6774 - accuracy: 0.5915\n",
            "Epoch 5/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.5818\n",
            "Epoch 6/30\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.6840 - accuracy: 0.5876\n",
            "Epoch 7/30\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.6759 - accuracy: 0.5857\n",
            "Epoch 8/30\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.6748 - accuracy: 0.5798\n",
            "Epoch 9/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6767 - accuracy: 0.5847\n",
            "Epoch 10/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6697 - accuracy: 0.6280\n",
            "Epoch 11/30\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.6658 - accuracy: 0.6154\n",
            "Epoch 12/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6719 - accuracy: 0.5876\n",
            "Epoch 13/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6603 - accuracy: 0.6251\n",
            "Epoch 14/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6403 - accuracy: 0.6685\n",
            "Epoch 15/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6509 - accuracy: 0.6621\n",
            "Epoch 16/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6369 - accuracy: 0.6738\n",
            "Epoch 17/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6458 - accuracy: 0.6358\n",
            "Epoch 18/30\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.6407 - accuracy: 0.6631\n",
            "Epoch 19/30\n",
            "69/69 [==============================] - 1s 7ms/step - loss: 0.6330 - accuracy: 0.6719\n",
            "Epoch 20/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6171 - accuracy: 0.6933\n",
            "Epoch 21/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6260 - accuracy: 0.6738\n",
            "Epoch 22/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6131 - accuracy: 0.6908\n",
            "Epoch 23/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6058 - accuracy: 0.6952\n",
            "Epoch 24/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.6045 - accuracy: 0.7006\n",
            "Epoch 25/30\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.5995 - accuracy: 0.6967\n",
            "Epoch 26/30\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.6049 - accuracy: 0.6986\n",
            "Epoch 27/30\n",
            "69/69 [==============================] - 1s 9ms/step - loss: 0.5982 - accuracy: 0.7064\n",
            "Epoch 28/30\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.6024 - accuracy: 0.6845\n",
            "Epoch 29/30\n",
            "69/69 [==============================] - 1s 8ms/step - loss: 0.5965 - accuracy: 0.7045\n",
            "Epoch 30/30\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.5934 - accuracy: 0.7016\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x23d5057c8b0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.fit(X_train_23, y_train_23, epochs=30, batch_size=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWQd4zdiatLv",
        "outputId": "4db1ce06-9f05-4957-cb0b-2d95936e424d"
      },
      "outputs": [],
      "source": [
        "def prediction_deep(dataset):\n",
        "    y_pred1 =  predict_model(Extra_Trees_Classifier, data=dataset)\n",
        "    y_pred1 =  y_pred1['prediction_label']\n",
        "    y_pred = []\n",
        "    for i in range(len(y_pred1)):\n",
        "        if y_pred1[i] == 1:\n",
        "            y_pred.append(y_pred1[i])\n",
        "        else:\n",
        "            value = (dataset.iloc[i].values)[np.newaxis, :]\n",
        "            prediction = predict_model(Linear_Discriminant_Analysis, data=dataset.loc[[i]])\n",
        "            y_pred.append(prediction['prediction_label'].iloc[0])\n",
        "    return y_pred\n",
        "\n",
        "def prediction2(dataset):\n",
        "    y_pred1 =  (model.predict(dataset) > 0.5).astype(int)\n",
        "    y_pred = []\n",
        "    for i in range(len(y_pred1)):\n",
        "        if y_pred1[i] == 0:\n",
        "            y_pred.append((y_pred1[i][0])+1)\n",
        "        else:\n",
        "            value = (dataset.iloc[i].values)[np.newaxis, :]\n",
        "            prediction = predict_model(Linear_Discriminant_Analysis, data=dataset.loc[[i]])\n",
        "            y_pred.append(prediction['prediction_label'].iloc[0])\n",
        "    return y_pred\n",
        "# def prediction2(dataset):\n",
        "#     y_pred1 =  (model.predict(dataset) > 0.5).astype(int)\n",
        "#     y_pred = []\n",
        "#     for i in range(len(y_pred1)):\n",
        "#         if y_pred1[i] == 0:\n",
        "#             y_pred.append((y_pred1[i][0])+1)\n",
        "#         else:\n",
        "#             value = (dataset.iloc[i].values)[np.newaxis, :]\n",
        "#             prediction = (model2.predict(value) > 0.5).astype(int)\n",
        "#             y_pred.append((prediction[0][0])+2)\n",
        "#     return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_app = pd.read_csv('abalone_app.csv')\n",
        "dummies = pd.get_dummies(data_app['sex'])\n",
        "\n",
        "dummies.columns = ['male', 'female', 'other']\n",
        "\n",
        "data_app = pd.concat([data_app, dummies], axis=1)\n",
        "\n",
        "data_app = data_app.drop('sex', axis=1)\n",
        "data_app = data_app.drop('male', axis=1)\n",
        "data_app = data_app.drop('female', axis=1)\n",
        "\n",
        "y_pred = prediction_deep(data_app)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " ...]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_pred2 = prediction2(data_app)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def accuracy(y_pred, y_pred2):\n",
        "#     if len(y_pred) != len(y_pred2):\n",
        "#         raise ValueError(\"As listas devem ter o mesmo tamanho\")\n",
        "#     correct = 0\n",
        "#     for i in range(len(y_pred)):\n",
        "#         if y_pred[i] == y_pred2[i]:\n",
        "#             correct += 1\n",
        "#     return correct / len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# accuracy(y_pred, y_pred2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " - Resposta do servidor:\n",
            " {\"status\":\"success\",\"dev_key\":\"AiDANO\",\"accuracy\":0.6373205741626794,\"old_accuracy\":0.64593301435407} \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Enviando previsões realizadas com o modelo para o servidor\n",
        "URL = \"https://aydanomachado.com/mlclass/03_Validation.php\"\n",
        "\n",
        "#TODO Substituir pela sua chave aqui\n",
        "DEV_KEY = \"AiDANO\"\n",
        "\n",
        "# json para ser enviado para o servidor\n",
        "data = {'dev_key':DEV_KEY,\n",
        "        'predictions':pd.Series(y_pred).to_json(orient='values')}\n",
        "\n",
        "# Enviando requisição e salvando o objeto resposta\n",
        "r = requests.post(url = URL, data = data)\n",
        "\n",
        "# Extraindo e imprimindo o texto da resposta\n",
        "pastebin_url = r.text\n",
        "print(\" - Resposta do servidor:\\n\", r.text, \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
